{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, requests, os\n",
    "\n",
    "# Set up paths and API URL from environment variables\n",
    "OLLAMA_API = os.environ.get(\"OLLAMA_API_BASE_URL\", \"http://localhost:11434\")\n",
    "MODEL_NAME = os.environ.get(\"OLLAMA_DEFAULT_MODEL\", \"llama3-instruct\")\n",
    "WORKSPACE_PATH = os.environ.get(\"WORKSPACE_MODELS_PATH\", \"/workspace/models\")\n",
    "\n",
    "model_dir = Path(WORKSPACE_PATH) / \"llama3\"\n",
    "\n",
    "# Read prompt from file using pathlib\n",
    "prompt_file = model_dir / \"prompts\" / \"explain_modelfile.txt\"\n",
    "prompt = prompt_file.read_text()\n",
    "\n",
    "# Make API request\n",
    "response = requests.post(\n",
    "    f\"{OLLAMA_API}/api/generate\",\n",
    "    json={\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print the response text\n",
    "print(response.json()[\"response\"])\n",
    "\n",
    "# Save the full response to a JSON file\n",
    "responses_dir = model_dir / \"responses\"\n",
    "responses_dir.mkdir(exist_ok=True)  # Create directory if it doesn't exist\n",
    "output_path = responses_dir / \"run1.json\"\n",
    "output_path.write_text(json.dumps(response.json(), indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
